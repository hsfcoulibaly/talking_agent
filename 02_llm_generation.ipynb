{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMHUyYWQKwtdLkpDavvNsAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsfcoulibaly/talking_agent/blob/main/02_llm_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai1-ll3uWVsV",
        "outputId": "4fe5194e-0071-4628-dfd7-65ce0ec0d806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# You can get a free API key from Google AI Studio (aistudio.google.com)\n",
        "genai.configure(api_key=\"AIzaSyAwuFlYY0obdgDEF_JaRIUeKRM286s1Q4s\")\n",
        "\n",
        "# Mock data simulating what LLaVA extracted from your game screenshot in Notebook 1\n",
        "extracted_data = {\n",
        "    \"environment\": \"Windrise, near a massive glowing oak tree\",\n",
        "    \"characters\": [\"Traveler (Player)\", \"Large Anemo Slime\"],\n",
        "    \"action\": \"Player using wind magic to disperse the slime\",\n",
        "    \"time\": \"Midday, bright sunlight\"\n",
        "}\n",
        "\n",
        "# The System Prompt (Injecting your professor's narrative rules)\n",
        "system_instruction = \"\"\"\n",
        "You are a weary traveling merchant resting off the main road.\n",
        "You are observing the player character from a distance.\n",
        "Based ONLY on the provided JSON event data, recount what you just witnessed in a short, immersive monologue (2-3 sentences).\n",
        "\n",
        "Strict Rules:\n",
        "1. Do not invent new characters, enemies, or environments not present in the data.\n",
        "2. Ensure the story is credible and dramatically meaningful.\n",
        "3. Express a sense of mystery about the player's abilities.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the model with the updated 2.5 model name\n",
        "model = genai.GenerativeModel(\n",
        "    model_name='gemini-2.5-flash', #\n",
        "    system_instruction=system_instruction\n",
        ")\n",
        "\n",
        "# Pass the extracted data to the model\n",
        "prompt = f\"Here is the visual event data I extracted: {extracted_data}\"\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(\"--- NPC GENERATED STORY ---\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "FwHcKAlGWgdd",
        "outputId": "b001bc46-f877-41e2-e442-f3eddc18c307"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NPC GENERATED STORY ---\n",
            "From a distance, under the bright midday sun near that massive glowing oak in Windrise, I just saw the Traveler. They faced down a hulking Anemo Slime, and with a mere gesture, they commanded the very winds to simply... disperse it. To wield such power over the elements, as if it were nothing, leaves one truly wondering what hidden depths that one possesses.\n"
          ]
        }
      ]
    }
  ]
}